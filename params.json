{
  "name": "Scazlab2016",
  "tagline": "A repo for the code I write in preparation for and while working at Yale's Social Robotics Lab for 2016",
  "body": "I am using this page as a resource to document my work leading up to, in and preceding my third summer in the [Social Robotics Lab](http://scazlab.yale.edu/). The finalized version of this document should be completed by the end of November 2016 with five deliverables: a review paper that demonstrates my work leading up to the lab, a daily blog detailing my work while in the lab and a final paper, presentation and poster that wrap up my work and my results.\r\n\r\nA brief disclaimer that this blog currently serves as a resource for myself more than anything else, as such, I have pointers to code that has not been posted as the code is currently part of active research. \r\n\r\n#Preparation\r\nThe main aspect of this section will be the review paper I wrote in preparation for the lab. I will also outline some of the work I did leading up to this paper including the papers I read and the lectures I watched. I hope to get all of this up in the near future. (todays date: 6/14/16) \r\n#Working in Scaz Lab\r\n\r\n###6/13/16\r\nThe first project I am doing with Alessandro and Olivier is using deep learning to recognize letters and digits off [snap circuits](http://www.snapcircuits.net/). I believe this is part of a broader effort within social hierarchical learning but I will confirm later. \r\nIn order to use deep learning I first must build a dataset to train on. That is what I am currently working towards and hope to be doing Wednesday. Until then I am preparing to run Olivier's code in an Ubuntu virtual machine. A lot of today was spent downloading and installing the necessary programs. However, after I finished I had run out of space in my virtual machine, a problem that is taking a lot longer than I expected to solve.  Tomorrow I plan to run Olivier's code which segments the image between the pegs. I spent a couple of hours looking through it today and figuring out which code does what and what dependencies his code has.  \r\nIn the future I hope to take the segmented images and train a neural net on them using the [Tensorflow](https://www.tensorflow.org/) library.\r\n\r\n###6/14/16\r\nAfter a few hours trying to figure out how to expand the virtual machine I ended up making a mistake which caused a blank black screen after opening. Frustrated, I decided to start over and created a far larger virtual machine that should be very difficult to fill. After re-downloading all the programs and setting things up again I ran into this issue with opencv when I tried to run the code:\r\n\t\r\n\tcv2.error: -------src-dir-------/opencv-2.4.10/modules/highgui/src/window.cpp:501: error: (-2) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Carbon support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function cvShowImage\r\n\t\r\nUnfortunately I downloaded opencv using standard the built in library within ubuntu so I could not find a way to make the change it called for without compiling from source. So following the advice on [this page](\r\nhttp://ubuntuforums.org/showthread.php?t=1916062) I began following [this tutorial](\r\nhttp://www.samontab.com/web/2014/06/installing-opencv-2-4-9-in-ubuntu-14-04-lts/) which did not fully compile on my first pass through the tutorial. At 6:30 I called it quits and I plan on picking it back up tomorrow.\r\n\t\r\n\t\r\n###6/15/16\r\nOn my way to work today I ate it on my skateboard and hurt my wrist pretty bad. Although I thought I would be fine, upon arriving at the lab there was a huge lump below my thumb and I was having a lot of difficulty moving my hand and my fingers. Worried I broke my wrist I decided to go get xrays and see a doctor. Luckily, I came away without a break and  just a bad sprain. I'll know more next Wednesday about the severity of the injury. As a result of all of this (and the network being down at my house) I was unable to get work done today.\r\n\r\n###6/16/16\r\nPicking up where I left off Tuesday, I continued with the tutorial. After getting through only about 20% of the install I decided that my issue must have been in my installation of cmake. So I reinstalled cmake from source before lunch following [this tutorial]( \r\nhttp://askubuntu.com/questions/610291/how-to-install-cmake-3-2-on-ubuntu-14-04). It worked until I ran into another error around 76% which I was able to circumvent using [this tutorial](\r\nhttps://gist.github.com/melvincabatuan/8dc300531e84822d368c). Finally, I was able to install opencv; however, 2when I ran Olivier's code I again received the same error. Currently I am unsure how to continue and I figure I will just try to run this code on another machine.\r\n\r\nAlessandro also took some time to show me how to use [Baxter](http://www.rethinkrobotics.com/baxter/)  today. Here are some important commands that I need to remember:\r\n\r\n\t3989  cd ros_devel_ws/\r\n\t3990  catkin_make\r\n\t3991  rospack profile\r\n\t3992  source devel/setup.bash \r\n\t3993  rospack profile\r\n\t3994  ls src/\r\n\t3995  roslaunch snap_circuits board_calibrator.launch \r\n\t3996  history\r\n\t\r\nImportantly I am using a different set of code then I was using before called boardcalibrator. This code defines the edges of the board and manipulates the image of the board the computer sees independent of the camera angle. **Picture of before and after as well as a general picture of the setup of experiment**.  My goal for tomorrow is to be able to run the code with the camera. \r\n\r\n###6/17/16\r\nI made progress today but was not able to run the code with the camera and I will have to get around to it Monday. Today revolved around installing and learning to work with [ROS Indigo](http://wiki.ros.org/indigo). This entails going through the tutorials. My goal is to figure out how to run the command\r\n\r\n\troslaunch snap_circuits board_calibrator.launch\r\n\t\r\nRunning it require a good amount of file configuration so that is what I have spent my day doing. My prospective schedule is as follows: by the end of Monday I hope to have begun building the dataset through taking pictures of each piece, I will most likely devote all of Tuesday to taking these pictures, the beginning of Wednesday will be applying Olivier's code to the photos I took, the end of Wednesday will be devoted to learning to work with TensorFlow and ensuring the ability to apply it to the small dataset Olivier has already built. It is highly probable that my work with TensorFlow will spill into Thursday but hopefully I can get through it Wednesday. Optimistically, however, I would then go on to classifying all the photos I took Tuesday on Thursday and the first half of Friday before training a neural net on the data Friday. Monday would then be devoted to merging it with Olivier's code and ensuring its function on Baxter along with beginning a formal write-up of the project to ensure I understand the motivations of the project as a whole. Pessimistically, this whole process takes until Tuesday or even Wednesday. I hope this is not the case however. \r\n###6/20/16\r\nI struggled again to run the code today.  Predominantly my day was spent just trying more tutorials and installing ROS dependencies for the code after running into errors. Below are the pieces I am trying to classify on a 7x10 grid of pegs. \r\n\r\n\r\n###6/21/16\r\nI finally figured out how to run roslaunch today on own computer. However, I then quickly had an issue with the camera I was trying to use and spent a while trying to locate a new one. Then, much to my disappointment, instead of running smoothly I got the error\r\n\r\n\t[usb_cam-1] process has died [pid 12797, exit code -11, cmd /opt/ros/indigo/lib/usb_cam/usb_cam_node __name:=usb_cam __log:=/home/george/.ros/log/1954eca6-37f3-11e6-a0d7-000c29f19534/usb_cam-1.log].\r\n\tlog file: /home/george/.ros/log/1954eca6-37f3-11e6-a0d7-000c29f19534/usb_cam-1*.log\r\n\r\nAfter a few hours of attempting solutions to problems that vaguely resembled mine in the forums I didn't understand what was wrong. In the office there is a computer that is used with Baxter that another intern is using, but all the code is on the computer and currently runs fine. Given this, I figured I must have had some newer version of the code that I downloaded off GitHub that hasn't been tested for errors yet. I sent myself all the files on the other computer hoping it would solve the problem; however, this was to no avail. I got the same error. Quite frustrating. Tomorrow I will either figure out how to run the code on my computer or resort to splitting time using the lab computer. \r\n###6/22/16\r\nStill couldn't get passed this. I looked through the log file to no avail and have been scratching my head on how to continue. I spent about 4 hrs but I also went to the Doctor who informed me that my fall the other day caused a hairline fracture in my arm. Before leaving, Olivier suggested that my openCV version might be the issue so I began the process of uninstalling 2.4.13 and installing the default 2.4.8 that comes with Ubuntu 14.04.\r\n\r\n###6/23/16 \r\nI started the day installing OpenCV 2.4.8 and then reinstalling ROS and CMAKE to get the code to run. Nevertheless I got the same error which convinced me that I had to use OpenCV 3. Fortunately, Alessandro got back today and interrupted me as I was trying to install the new version of OpenCV and he was able to get the code running with 2.4.8 in about 10 minutes. It turns out my computer did not like the resolution of the camera I was using and scaling it back to 480p from 720p solved my problem. I was then able to begin working on building the dataset and was able to completely photograph 2 pieces and begin a third. **The dataset can be found here** \r\n\r\n###6/24/16\r\nI continued building the dataset today, getting through the numbers and a pass at the length three pieces. Further, I began reading the documentation of Tensorflow. I would like to ensure that I can get Tensorflow working on Olivier's small dataset before I spend a day or two classifying the data I have collected. I don't want to have to reformat after if Tensorflow has any data specific requirements. \r\n\r\n###6/27/16\r\nToday I continued recording data, getting through the miscellaneous three length pieces and beginning the miscellaneous odd shaped pieces. I hope to learn more about Tensorflow tomorrow, going through a tutorial or two, before attempting to apply it to Olivier's data. By Wednesday I should be devoting my time to . \r\n\r\n###6/28/16\r\nToday I pretty much finished off taking pictures for the dataset. Odds are I have to go take more photos for some of the blocks; however, I will leave that for another day. Further I began the [MNIST For ML Beginners](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html) and hope to finish this tutorial and the [Deep MNIST for Experts](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html) tomorrow. I also hope to apply Olivier's code to some data I have collected now. By the end of tommorrow it would be great to have a neural net prepared to take the data I have collected and train upon it. This would allow me to focus on classifying the dataset Thursday and Friday and leave me finding just finding time to run it. \r\n\r\n###6/29/16 \r\nI spent most of today understanding Tensorflow through doing both the tutorials I highlighted yesterday and going through the documentation. The main question I had on my mind was how should I classify the dataset for use within Tensorflow. Further I also did some interesting (light reading](http://colah.github.io/posts/2015-09-Visual-Information/) on a cost function called \"cross-entropy\" that I had not come into much contact with. The most significant aspect of my day was a discussion I had with Olivier about the project and his code. It turns out I was reading part of the wrong code, and that he already has a great format for me to begin classifying the data. Further, he has already implemented a classifier and a quick and desigined a way to pull from the data format. So walking away from this meaning I was theoretically able to sit down and get to work on classifieing the data. \r\n\r\n###6/30/16 \r\nAlthough I was theoretically capable of beginning work on the classifier I ran into the same issue that I did a few weeks ago trying to execute the code. \r\n\t\t\r\n\tcv2.error: -------src-dir-------/opencv-2.4.10/modules/highgui/src/window.cpp:501: error: (-2) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Carbon support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function cvShowImage\r\n\r\nSo I spent my day going through tutorials trying to resolve the issue before discovering, with Alessandro's and Olivier's help, that the source of all my woes has been my installation of anaconda. After removing it I began reconfiguring parts of my environment to run again. At the end of the day I was still running into problems getting the code to run but I think with another hour it will be good to go. \r\n\r\n### 7/1/16\r\nBy lunchtime today I had Olivier's code up and running on my machine and I was ready to begin work on classifying the data. To do this I removed cmake and reinstalled it, then reinstalled ros, then created a new catkin_ws directory and then installed some dependencies that were specific to Olivier's code… but it finally all works fluidly. \r\n\r\nAfter lunch I played around with Olivier's code a little bit, trying to figure out what exactly I needed to do before I jumped into classifying the some 300 pictures I have. One of my main sources of annoyance was the fact that all the pictures would eventually have to be in one file which was a problem because the way I obtained the files saved them in a way that many of my pictures shared file names. Further all the pictures needed to be converted from jpg to png. To mitigate all of this I wrote a short piece of code:\r\n\t\r\n\tfor i in range(10): \r\n\t\tif i < 10:\r\n\t\t\tim = Image.open('Four/7/frame000' + str(i) + '.jpg') \r\n\t\telse:\r\n\t\t\tim = Image.open('Four/7/frame00' + str(i) + '.jpg') \r\n\t\tim.save('Four/boards/board_' + str(146 + i) + '.png') \r\n\t\topen('Four/boards/board_' + str(146 + i) + '.json','w')\r\n\r\nThe remainder of my day was spent reformatting the pictures. \r\n\r\n###7/11/16 through 7/22/16\r\nI spent this week classifying all the images I took. It was an ardouous process but it means I get to move onto more fun things with the data I collected. \r\n\r\n###7/18/16\r\nToday I spent my time attempting to train a classifier on the data I collected. I ran into errors twice 3 hrs into training unfortunately, so I am going to have to wait for tomorrow to get any concrete results. In the meantime I have been exploring tensorflow more and looking for ways that the classifier could potentially be improved. I spoke to Olivier about  what he thinks is the best way to move forward and at the moment I am tasked to just research, and take detailed notes both recording results and using GitHub to document code, the best ways to preprocess the data and the possibility of changing the algorithm. The first place I am going to look for this is what method those classifying the MNIST dataset used to achieve their highly successful result. I am also keeping it in the back of my mind that there is a very real likelihood I will have to add more data to the dataset and to more data classification to achieve a robust classifier. \r\n\r\n#My Research and Results\r\n\r\n#Conclusion\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}